# WEEK 9 : Anomaly detection
---
## 予備知識
### アノマリー
アノマリー(英語:Anomaly)とは、ある法則・理論からみて異常、または説明できない事象や個体等を指す。科学的常識、原則からは説明できない逸脱、偏差を起こした現象を含む。すでに説明できるようになった現象でも、アノマリーあるいは異常という名称がそのまま残ったものも多い。

---
## Problem motivation
　今後の一連のビデオで、**アノマリー検出**と言われる問題を扱いたい。これは割と良く使われる種類の機械学習で、そして興味深い側面の一つに、これはだいたい教師なし学習の問題でありながらまたある側面では教師有り学習の問題にとても似ている部分もある。 

　アノマリー検出とは何か？ それを説明する為に、やる気になりそうな例として、、、航空機のエンジンの製造者だとしよう。 そしてあなたの航空機のエンジンが組み立てラインからロールオフして、そしてQAをしている、つまり品質保証テストをしているとしよう。そしてそのテストの一貫として、航空機のエンジンのある機能ーーそうだなぁ、生成される熱とか振動とかを測っているとしよう。ずっと昔に私の友人達がこの問題に挑んでいてこれらのフィーチャーは本当に彼らが実際の航空機エンジンから集めた物だ。 あなたは今、X1 から Xm のデータセットを持っている。 m個の航空機エンジンを作ったとして、そのデータをプロットすると、こんな感じになるだろう。 この各点、各バッテンはあなたのラベル無し手本だ。 そしてアノマリー検出の問題は以下のような感じ。 翌日、新しい航空機のエンジンが組立ラインからロールオフしたとしてみよう。あなたの新しい航空エンジンは幾つかのフィーチャーの集合、x-testを持つ。アノマリー検出問題とはこの航空機エンジンがとにかく何かしら普通でないかを知りたい。言い換えると、たとえばこのエンジンをさらなるテストに回さなきゃいけないかを知りたい、またはこのエンジンは問題なさそうなのかを。 問題なさそうで、追加のテスト無しで客に出荷して良さそうかを。 つまり、その新しい航空機エンジンがそこの点なら うーむ、それ以前のたくさんの航空機エンジンと似てるので、たぶんOKそうでしょう。 一方、新しい航空機エンジンが x-testが、ここの点なら、つまりx1とx2がこの新しい手本のフィーチャーなら、x-testがはるかこの外にあるなら、それはアノマリーと呼んで良かろう。 だからたぶん、顧客に出荷する前に追加のテストに送り出しても良いといえよう。 だってこのエンジンは、それ以外に見た物と大きく異なっているから。より正式には、アノマリー検出の問題ではなんらかのデータセットが与えられて、それは x1 から xm までの手本としておく、そして、普通はこれらのm個の手本をノーマル、またはアノマリーでは無い、と想定する。そしてある新しいサンプル、x-testが来た時にに、それがアノマリーっぽいかをアルゴリズムに教えて欲しい。その為に我らがとるアプローチは与えられたデータセットに対しラベル無しのトレーニングセットが与えられた時に モデルp(x)を構築する。 言い換えると、xの時の確率のモデルを構築するということ、ここで xはこれらのフィーチャー、例えば航空機のエンジンとかの。 

そしてxの時の確率のモデルを構築して、新しい航空機エンジンに対し、 p(x-test)が、 あるエプシロンより小さいかを見る。 そしてこれがアノマリーかどうかのフラグをつける。 つまり新しいエンジンでデータから推計したモデル、p(x)による確率がとても小さいのを見かけたら、これをアノマリーとフラグをつける。もしp(x-test)が、例えばある小さな閾値より大きければそれはオーケーっぽいと言うわけ。 そして与えられたトレーニングセットがここにプロットしたような物だとして、 以下のようなモデルを構築して、 航空機エンジンの、、、 いや、モデルp(x)に、どこかこの中のあたりに ある点に対しては、 とても高い確率だと言って欲しく、 他方、ちょっと離れた所にある点には、低い確率だと言って欲しい。さらに遠く離れた点に対しては なんらかの、より低い確率になって欲しい。 そしてこの離れた点や この離れた点は アノマリーだろう。 他方ここにある点、 ちょうどなかほどにある点、 これはOKだろう、 だってp(x)は なかほどの点に対しては とても高くなるだろうから、だって その辺にはたくさんの点が見られているから。 

　これはアノマリー検出の応用の一例だ。 たぷん一番一般的なアノマリー検出の 応用例は、たくさんのユーザーが居て、各ユーザーが異なるアクティビティを行なっている時に、たとえば webサイト上とか物理的な工場とかそういうので、各ユーザーごとのアクティビティの フィーチャーを計算する事が出来る時に、モデルを構築して、いわば、異なるユーザーが別々の行動をとる確率を言わせる事が出来る。 ユーザー行動を表すフィーチャーのあるベクトルがどの位の確率となるのか、たとえばユーザーアクティビティのフィーチャーの例としては、 webサイトの場合なら、x1がユーザーのログインの頻度で、x2は、うーん、訪問したページの総数とか、取引の総数で、 x3は、うーん、そのユーザーがフォーラムにポストした投稿の総数で、フィーチャーx4はユーザーのタイピング速度とかの可能性だってありえる。 実際一秒あたりのユーザーのタイプした文字速度を トラックしているwebサイトもある。 そしてこんな類のデータに対して、p(x)をモデリング出来るわけだ。そして最後に、その得られたモデルp(x)を使って、あなたのwebサイトで 凄く奇妙な行動をとっているユーザーを特定する事が出来る、どのユーザーが確率的にエプシロン以下なのかをチェックする事によって。そしてそれらのユーザーのプロファイルをさらなるレビューに送り出すとか、または、それらのユーザーからは追加の身分証明を提出させるとか、そういう、あなたのwebサイトを奇妙な行動や 詐欺っぽい行動からガードする何らかの措置を講ずるのだ。 

この種の技術は、 普通でない行動をしているユーザーをフラグ付けしてしまい、それは必ずしも不正をしているユーザーだけとは限らない。 つまりいっつも盗みを働いているユーザーだけじゃなくたんにふざけてるだけのユーザーも。普通でないユーザーを探すだけ。だがこれは実際にたくさんの商品を販売している オンラインwebサイトにおいて、詐欺行為をしているか不正にのっとったアカウントを使っている事を示す事を期待すべく、奇妙な行動をとっているユーザーを見つける為に使われているテクニックだ。 アノマリー検出のもう一つの応用例は製造業だ。 航空機エンジンのケースを既に話したが、そこでは普通とは異なる航空機エンジンを見つけ出して、それらをさらなるレビューへと送り出すのだった。 

　三番目の応用例はデータセンターのコンピュータをモニタリングするという事。これに実際に従事してる友達が何人かいるよ。 コンピュータのクラスタなりデータセンターなりにたくさんのコンピュータがあったとして、各マシンのフィーチャーを計算出来る。 例えばどれだけのメモリを使ってるかとかディスクアクセスの総数だとかCPU負荷だとかもっと複雑なフィーチャーでも良い、このマシンのCPUロードをこのマシンのネットワークトラフィックの量で割ったりだとか、そういう物を捉えたようなフィーチャー。 そしてデータセンターの通常時の振る舞いのデータを与えられた時に、xとなる確率をモデリング出来る。 つまりこれらのマシンが 様々なメモリ使用量となる確率、またはこれらのマシンが様々なディスクアクセスの回数となる確率、様々なCPU負荷となる確率などをモデリング出来る。そしてもし確率xが、 p(x)が とても小さいマシンがあったら、そのマシンは普通でなく振舞ってるという事が分かり、そのマシンは落ちる所かもしれないので それをフラグ付けして システム管理者にレビューさせたり出来る。 そしてこれは実際に、 こんにち様々なデータセンターで自分たちのマシンに普通でない事が起きていないか監視するのに使われている。 

以上がアノマリー検出。 次のビデオではガウス分布とガウス分布の性質をちょこっと議論し、そしてその後のビデオで アノマリー検出のアルゴリズムを 開発するのにそれを使っていく。 


## Gaussian Distribution (ガウス分布 / 正規分布)

このビデオでは、 ガウス分布について議論したい、 それは正規分布とも呼ばれる。もしガウス分布に既に十分に慣れ親しんでいるのなら、たぶんこのビデオはスキップしてOKだ。 だがもしあんま自信無かったり ガウス分布または正規分布を使っていた頃から随分と時間が経っているのなら、このビデオを終わりまで見てみてください。そしてこのビデオの後には、アノマリー検出のアルゴリズムを開発する為にガウス分布を用いていきます。 

xは実数のランダムな数とします。つまりxは実数です。もしxの確率分布がガウス分布で、平均ミューと分散シグマ二乗である事をこう書ける: ランダム変数x チルダ ここでこの小さなチルダ記号の意味する所は分布が等しいという事で、その後にガウス分布を記述する訳だが、それには、記号のNにかっこでミュー、シグマ二乗と書く事になっている。つまりこの記号NはノーマルのN、だってガウス分布は正規（ノーマル）分布だから。それは同じ意味で、 Normalの省略系でガウス分布は2つのパラメータでパラメトライズされてる、という事を表す。 2つのパラメータとは平均を表すミューとシグマ二乗で示される分散のパラメータ。 ガウス分布またはガウス確率密度をプロットすると、ベル型のカーブとなる、見たことあるかもしれないね。そしてつまり、このベル型のカーブは2つのパラメータ、ミューとシグマでパラメトライズされてる。このベル型のカーブの中心は平均のミューで、そしてこのベル型のカーブの幅がだいたい、このパラメータシグマであり、1標準偏差とも呼ばれている。 

これはxが 様々な値を取る確率を示している、つまりxがこの真ん中の値を取ると、極めて高くなる。なぜならガウス分布のここはとても高い一方で xがこの遥か離れた所の値を取る場合は 確率は減衰するだろう。 最後に、完璧を期するという目的の為だけに、 ガウス分布の式を書き下しておこう。xの確率は、、、 ところでたまに、p(x)と 書く代わりに、これをpのxに セミコロンでミュー、シグマ二乗とつなげて書くことがある。これはxの確率は2つのパラメータミューとシグマ二乗でパラメトライズされている事を示す。 そしてガウス密度の式はこれだ。 2パイのシグマ分の一のeのマイナスx引くミューの二乗割ることの2シグマ二乗。 この式を暗記する必要は無い。 これは単にここの左にあるベル型のカーブの式ってだけに過ぎない。 それを暗記する必要は無いし、もしこれを使う必要が出てきても、その時調べれば良い。以上がこの左にある図でこれがミューとシグマを固定して p(x)をプロットしたら得る物だ。 このここのカーブ、これがミューとシグマ二乗、つまり分散を固定して p(x)をxの関数として プロットした物だ。 時には（シグマ二乗より）シグマで考えた方が楽な事もある。 シグマは標準偏差と呼ばれる物でそれはガウスの確率分布の幅を規定するもので、 一方シグマ二乗、シグマの二乗は分散と呼ばれる物。 ガウス分布が実際にどんな感じか、例を見てみよう。 

ミューが0でシグマが1だとすると、ゼロを中心に持つガウス分布となる、何故ならそれはミューの事で、ガウス分布の幅はつまり1標準偏差はここのシグマとなる。 ガウス分布の例を見てみよう。 ミューが0でシグマが1の時はゼロの所を中心とする ガウス分布に対応する、何故ならミューが0だから。 そしてガウス分布の幅は、、、ガウス分布では幅はシグマにより、つまり分散のパラメータ、シグマにより制御されている。もう一つの例はこんな感じ。ミューが0でシグマが1/2としよう。つまり標準偏差が1/2で 分散、シグマ二乗は 0.5の二乗、つまり 0.25となる。 その場合、ガウス分布、 ガウス確率密度はこんな感じとなる、今回もゼロを中心としているが、 だが今回は幅が より狭くなっている、 何故なら分散が小さくなったから。 ガウス密度は だいたい半分の幅となっている。 だがこれは確率分布なのだから、 カーブの下の面積、 つまり影をつけた部分は、 積分すると 必ず1となる。 これは確率分布の性質だ。 
また、そうであるから、これはより背の高いガウス密度となる、だって標準偏差が半分だから幅も半分になるので、高さは二倍となる訳だ。 もう一つ例。シグマが2だと より太った、またはより幅の広いガウス密度となる。 つまりここでは、パラメータのシグマはガウス密度がどれだけの幅を持つかを制御している。 そして今回も、曲線の下の面積はこの影をつけた領域だが、 それはいつでも積分すると1となる。 それは確率分布の性質で今回はより幅が広くなったのだから、高さは半分になっている、積分した結果が同じになるように。 そして最後に、最後の例は、ミューも同じように変更していった場合、ゼロを真ん中に分布する代わりに、 ここでは3の回りに 分布するガウス分布を 得る。 何故ならこれはガウス分布全体をシフトさせるから。 

次にパラメータの推計の話題にうつろう。 パラメータの推計問題とはなんだろう？ m個の手本データセットがあるとしよう。つまりx1からxmまで。 そしてこれらの手本の個々は 実数だとしよう。 この図で、私は手本のデータセットをプロットした。 横軸はx軸で 手本のデータは、 xがある範囲に広がっている。それをここに 単純にプロットしてみた。 そしてパラメータ推計の問題は これらの手本がガウス分布だったと思っているとして、 つまりこの各手本x(i)が以下のように分布、、、 それがこのチルダの意味だったね。 で、これらの各手本が、正規分布またの名をガウス分布に従って分布していると 思ってるとする、 あるパラメータ、ミューとシグマ二乗の。 

だが、これらの値が幾つかは知らない。 パラメータ推計の問題とは、与えられたデータセットに対して、 ミューやシグマ二乗の値が 何になるのかを推計したい、という事。 もしこんなデータセットを与えられたら、 どんなガウス分布からこのデータが生成されているかを 推計したら、 多分だいたいミューを中心としてシグマ、つまり標準偏差がこのガウス分布の幅をコントロールしている。 これはだいたいデータにリーズナブルにフィットしている。何故ならデータは見た感じ中心のあたりにとても高い確率を持っていて、外に離れれば離れる程低い確率となっている。 だからこれはたぶんミューとシグマ二乗のリーズナブルな推計となっている。 つまり、そのデータがガウス分布に 従っているのなら、それはこんな見た目のはずだ。 

そこで私は、こうする: 式、つまり正規分布の式を書き下して、 パラメータのミューとシグマ二乗を推計する。 ミューを推計する方法は単に平均をとるだけ、手本の全体にわたって。 ミューは平均のパラメータだから。 つまりトレーニングセットから、 m個の手本から、それらの平均をとる。それは単にこの分布の、中心を与える。 

ではシグマ二乗はどうか？ 分散に関しては、また通常の式を書き下すと、1からmまでに渡り、x(i)からミューを引いた物の二乗の和を計算する。ここでこのミューはこの式を使ってここで計算したものだ。 そして分散とは何か、というと一つの解釈としては、この項を見ると分かるように、手本の値と平均との差の二乗となっている。 つまり中心との差、分布の平均との差の。 そして分散を、差分、つまり手本と平均との間の差分の二乗の平均として 推計する訳だ。 ここでちょっと補足しておくと、 あなたが統計のエキスパートだったら統計のエキスパートだったら最尤法という物について聞いたことがあるかもしれない。 そうであるなら、これらの推計は実際には最尤法によるパラメータ、ミューとシグマ二乗の推計である。だがもしそれについて聞いた事が無ければ気にしないでよろしい。 知らなくてはいけない事の全てはこれら2つの公式が所与のデータセットに対して、 ミューとシグマ二乗を見つけ出す標準的な方法だとという事だけだ。 

最後にもう一つおまけ。 これもまた、以前に統計のクラスを取った事のある人向けの話だ。 以前に統計のクラスを取った事があるなら、ここにある式を以前に見た時は mではなくてm-1 だったかもしれない。 つまりの最初の項が、 1/mではなくて、1/(m-1)に なる。機械学習では 1/mの式が使われる事が多い。 だが現実問題としては、 1/mだろうが 1/(m-1)だろうが、 本質的には大差無い、 mが普通に考えられる程度に大きい、つまりトレーニングセットのサイズが普通に大きければ。ようするに、以前に別のバージョンの方を見た事があった場合の為に補足しておくと、どっちのバージョンでもちゃんと機能する。だが機械学習では多くの人々は この公式の1/mの方を使う傾向にある。 2つのバージョンは理論的にはわずかに異なった特徴があり、 わずかに異なった数学的な特徴があるが、現実の場面ではほとんど違いは無い。 

以上で、ガウス分布がどんな感じか、感覚的に分かるようになってくれただろうか。 パラメータ、ミューとシグマ二乗のガウス分布における推計の仕方も 分かってくれただろうか。 トレーニングセットを与えられた時、ガウス分布に従ったデータだと思われるがそのパラメータ、ミューとシグマ二乗が不明な時。 

次のビデオでは、これを用いて、 アノマリー検出のアルゴリズムを開発するのに適用していく。 


## Algorithm
　前回のビデオでは ガウス分布について話した。 今回のビデオではそれを用いて アノマリー検出のアルゴリズムを開発する。 ラベル付けされていない m個の手本があるとしよう。 これらの手本の個々は R nに属するフィーチャーと なっている。 つまりトレーニングセットは例えば 製造した直近m個の 航空機エンジンのフィーチャーベクトルでも良し、 m人のユーザーのフィーチャーでも それ以外の何かでも良い。 アノマリー検出に どうアプローチしていくか、というと、 データセットからp(x)を モデリングしていきます。 どんなフィーチャーの組みの確率が高くてどんなフィーチャーの組みが低い確率なのかを 見つけ出したい。 で、xはベクトルなので、 p(x)をモデリングするとは x1の確率、、、ここで x1はxの最初の成分ですが、 x1の確率に、 掛けることのx2となる確率、 これは二番目のフィーチャーの確率で、 それに掛けることの 三番目のフィーチャーの確率、 などなどと、 最後のフィーチャーxnの確率まで 掛け合わせます。 ここにスペースを空けたのは、あとでここに書きたい事があるからです。 
　
　で、これらの個々の項、 p(x1)、p(x2)などを どうモデリングするのでしょうか？ どうやるかというと、 x1がガウス分布に従って 分布していると 想定します、なんらかの平均、 それをミュー1と 書きましょう、 そしてなんらかの分散、 それをシグマ二乗の1と書くことにしましょう。 そしてp(x1)は 平均がミュー1で 分散シグマ二乗1の ガウスの確率分布に従うとする。 同様に x2はガウス分布に従って分布していると、、、 ところで、 この小さなチルダ記号は （右辺に従い）分布している、という事を意味する。 で、平均がミュー2で分散がシグマ二乗の2の ガウス分布に従っている、つまり異なるガウス分布に従って 分布している、と想定する。 それは異なるパラメータのセット、ミュー2とシグマ二乗の2を持っている。 同様に、 x3もまた別のガウス分布で、 これもまた 他のフィーチャーとは異なる 平均と標準偏差を持ちえる。 などなどと、xnまで続く。 以上が私のモデルとなる。 

あなたたちの中のうち、 統計のスペシャリストの人向けの余談ですが、 私の書き下した方程式の 実際にはフィーチャーの値、 x1からxnまでの値が 独立である事を 仮定している。 だが実際には、 ここに書いたアルゴリズム片は、 これらのフィーチャーが 独立に近いかどうかに関わらず機能する、 実は独立の仮定が成り立たない時ですら このアルゴリズムはうまく機能する。 だけどもしあなたが、たった今、私が使った 独立の仮定だとかの用語の意味が分からなければ 気にしないでよろしい。 そのうち分かるようになるだろうし、 このアルゴリズムは正しく実装出来るだろうから。 さきのコメントは単に統計の専門家向けのコメントに過ぎない。 

最後に、これのまとめとして、 この式を もうちょっとだけコンパクトに書く。 これを、以下のように jが1からnまでの 以下のpの積として書くことにする。 pのxjで、xjは ミューjとシグマ二乗jで パラメトライズされている。 つまりこのファニーな 記号、大文字の ギリシャ文字のアルファベット、パイだが、 そのファニーな記号は、値の集合に対して 積をとる事に対応する。 つまり、和の記号に 慣れているなら、 iを1からnまでのiの 和を取ると、 この意味は1+2+3+... とnまでの和という意味。 一方このファニーな 記号は、この掛け算記号は、 iが1からnまでの iの掛け算。 これの意味する所は 和の記号とほとんど同じだけど、今回は足す代わりに掛け算する、という意味。 これは結局、1掛ける 2掛ける3掛ける、、、と、nまで掛ける。 で、この積の記法を 使うと、 このjが1からnまでこの式を掛け合わせる、というのを使うと もっとコンパクトになる。 これらの項全部を 書く、より短い 方法となるワケ。 だってこれらのpの、ミューjとシグマjが 与えられた時のxjの 値をとって、 それらを掛け合わせているのだから。 ところで、このpのxという 分布を推計する問題は 密度推計の問題、と呼ばれる事がある。 それがこのスライドのタイトルでもある。では、全部合わせると、我らのアノマリー検出のアルゴリズムはこうなる。 最初のステップはフィーチャーを選ぶ事、 または見つけ出すことだ、 アノマリーであるサンプルを示してくれると 思われるようなフィーチャーxiを。 つまり、どういう意味かというと、 以下のようなフィーチャーを 探し出すという事です: あなたのシステムに 詐欺行為を働いているかもしれない 普通でないユーザーが いた時に、または航空機エンジンの 例では、何かおかしな事、 何か奇妙な事が航空機エンジンに起こっている時には 普通でないほど大きな値、 または普通でないほど小さな値をとる、とあなたが思うようなフィーチャーxiを選ぶ、 アノマリーのサンプルが どんな感じかを知る為に。 またはより一般的に、 集めているデータの対象の一般的な性質を良くとらえているフィーチャーを集めても良い。 次に、得られたm個のトレーニングセットに対し、 ラベル無し手本に対し、x1からxmまでに対し、 パラメータをフィットさせる、 ミュー1からミューnまでと、 シグマ二乗の1からシグマ二乗のnまで。 これらの式は 前回のビデオでやった 式と似ている。 これらのパラメータの推計に この式を使っていく。 いくつか解釈を与えておくと、 ミューj、 これはフィーチャーjの平均だ。 そしてこのミューjはpのxjの式に パラメータとして入る、それは ミューjとシグマ二乗jでパラメトライズされていたのだった。 だからこれの言ってる事は ミューjは単に トレーニングセットに渡って フィーチャーjの平均を取った物、という事。 そして補足しておくと、 あなたは、これらの式を jが1からnまでに渡って 計算することになる。 つまりこれらの式を使ってミュー1、 ミュー2、と ミューnまで、推計する。 シグマ二乗も同様だ。 そしてまた、これらの ベクトル化したバージョンを作る事も可能だ。 ミューをベクトルとして 考えると、 つまりミュー1があって、 ミュー2があって、、、と ミューnまで。すると ベクトル化したバージョンの パラメータのセットは 1からnまでの xiの和と書ける。 つまり今書いたこの式で このxiをフィーチャーベクトルとして n個全てのミューの値を 同時に推計する。 そしてまた、シグマ二乗jの 推計についても ベクトル化した式を作れる。 

最後に、新しいサンプルを与えられたら、 つまり、新しい航空エンジンが来て、 この航空機エンジンがアノマリーなのかどうかを知りたいとすると、やらなくてはならない事は p(x)を、この新しいエンジンの確率を計算する事だ。 で、p(x)は この積と等しくて、 実装としては、計算するのは、 この式で、 ここにある、これは ガウス確率の 式だ。 だからこれを計算し、 最終的に、この確率が とても小さければ、 これをアノマリーとフラグづけする。 これはこの手法の適用例だ。 このスライドの左上に プロットしたようなデータがあるとしよう。 もしこの、フィーチャーx1を見てみると、 もしこのデータセットを見てみると、 見た感じだいたい フィーチャーx1の平均は5のあたりで、 標準偏差は このデータセットのx1の値だけを 見ると、標準偏差は だいたい2くらい。 つまりそれがシグマ1。 そしてフィーチャーx2の 値を見ると、 それは縦軸で測れて その平均は見たところ だいたい3くらいで、 標準偏差はだいたい1。 だからこのデータセットに対して ミュー1、ミュー2と、シグマ1、シグマ2を 推計すると、これが得られる物だ。 ここでもまた、シグマとここに書いた。 標準偏差について考えているけれど、 前のスライドの式は これらの二乗の推計を与える物だった。 つまりシグマ二乗の1、シグマ二乗の2。 だから、シグマ1とシグマ2を使ってるのか それともシグマ二乗1とシグマ二乗2を 使ってるのかに、注意しなさい。 そしてシグマ二乗1はもちろん、 イコール4となる。 2の二乗だから。 図では、 ミュー1とシグマ二乗1で パラメトライズされている p(x1)と、 ミュー2とシグマ二乗2で パラメトライズされたp(x2)は ここにあるこれら2つの分布のような見た目となるだろう。 そして結局、 p(x)をプロットすると それはこれら2つの 積だったのだから 実際にはこんな感じの 平面プロットが得られる。 これはp(x)のプロットで その高さ、 この上の高さ、 平面上のある特定の点の 高さは、つまりある x1、x2が与えられた時に x2の値が2で x1の値が2なら、この点だ。 そしてこの三次元平面の高さが それこそがp(x)だ。 つまりp(x)、それがこのプロットの 高さだ。 それは文字通りミュー1とシグマ二乗1で パラメトライズされたp(x1) 掛けることの ミュー2とシグマ二乗2で パラメトライズされたp(x2)である。 つまり、これがパラメータを このデータにフィットさせる方法だ。 新しいサンプルが幾つか来た場合を考えてみよう。 新しいサンプルはここかもしれない。 これはアノマリーか？そうでないか？ また、それとは別のサンプルが、 例えば二番目のサンプルがここにあるとしよう。 これはアノマリーか？そうでないか？ それを区別する方法は ある値エプシロンをセットする、 ここではエプシロンを 0.02としたとしよう。 どうやってエプシロンを選ぶかは後で話す。 まずは最初のサンプルを 取ってみよう。このサンプルを x1 test と呼ぶ事にする。 そして二番目のサンプルをx2 testと呼ぶことにする。 で、どうするかというと、 p(x1 test)を計算する。 その為に、この式を使って それを計算する。 これは見たところかなり大きな値に見える。 特に、これはエプシロン 以上となっている。 だからこれは、きわめて大きい確率で 少なくともエプシロンより大きいとは言える。 だからx1 testはアノマリーでは無い、と 言って良かろう。 一方 p(x2 test) を計算してみると、 これはもっとずっと小さい値となる。 これはエプシロンより小さい。 だから、これは確かに アノマリーだと言える。 何故ならそれは、我らが選んだエプシロンより小さいから。 そして実際、ここで言った事は、 これの本当に意味している事は、三次元での表面プロットを見ると、それの言わんとしている事は、 その点の上の 表面までの高さが高い点となるx1，x2は、全て 非アノマリーのサンプルに、つまりOKというかノーマルなサンプルに 対応しているという事。 一方、遥か離れたこの辺の点は全て 遥か離れたこの辺の点は全て、 これらの点は全て とても低い確率となっている。 つまり、我らとしては、 これらの点をアノマリーと フラグづけする事になる。つまりある領域を それはこんな感じとなるだろうが、 その外の全ての点を アノマリーとフラグづけ する事となる。 

一方で、このエプシロンの内部に ある物たちは、ここに書いたように、 これはOK、または非アノマリーなサンプルとみなす。 つまりこのサンプルx2 testは その領域の外に位置しているので つまりそれはとても低い 確率なので、それはアノマリーのサンプルとみなす訳だ。 

このビデオでは、どうやってp(x)を推計するかを 議論してきた。xとなる確率を。 アノマリー検出のアルゴリズムを 開発する為に。 そしてこのビデオではまた、 所与のデータセットに対して パラメータをフィッティングする、 パラメータを推計する全体の手順も見ていった。 パラメータであるミューとシグマを取得して、 次に新しいサンプルに対して それがアノマリーかどうかを判断した。 

次のビデオでは、 このアルゴリズムに対してより深く見ていく。 そしてこれを実際にうまく運用する為に ちょっとした補足の話もしていく。 